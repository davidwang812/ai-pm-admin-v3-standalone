# AI服务中心完整测试计划

## 测试概述

本文档包含AI服务中心的完整测试计划，覆盖功能、集成、性能、安全和契约合规等多个维度。

## 一、功能测试

### 1.1 服务商配置模块

#### 测试用例 TC001: 添加新服务商
- **前置条件**: 管理员已登录
- **测试步骤**:
  1. 进入服务商配置页面
  2. 输入服务商信息（名称、API密钥、端点）
  3. 选择启用状态
  4. 点击保存
- **预期结果**: 
  - 服务商成功保存
  - 显示成功提示
  - API密钥被加密存储

#### 测试用例 TC002: 测试服务商连接
- **前置条件**: 已配置服务商
- **测试步骤**:
  1. 点击"测试连接"按钮
  2. 观察响应时间和状态
- **预期结果**: 
  - 显示连接状态（成功/失败）
  - 显示响应时间
  - 失败时显示具体错误信息

#### 测试用例 TC003: 修改服务商配置
- **前置条件**: 已有服务商配置
- **测试步骤**:
  1. 修改服务商参数
  2. 保存更改
- **预期结果**: 
  - 配置更新成功
  - 历史配置被记录

### 1.2 统一配置模块

#### 测试用例 TC004: 全局参数设置
- **测试步骤**:
  1. 设置全局Temperature、Top P、Max Tokens
  2. 为每个AI服务配置独立参数
  3. 保存配置
- **预期结果**: 
  - 配置保存到SYSTEM_CONFIGS表
  - 参数验证通过（范围检查）

#### 测试用例 TC005: 配置导入导出
- **测试步骤**:
  1. 导出当前配置为JSON
  2. 修改JSON文件
  3. 导入配置
- **预期结果**: 
  - 导出文件格式正确
  - 导入验证配置合法性
  - 导入后配置生效

### 1.3 负载均衡模块

#### 测试用例 TC006: 创建负载池
- **测试步骤**:
  1. 创建新的负载均衡池
  2. 选择负载策略（轮询、加权、最少连接等）
  3. 添加服务商成员
- **预期结果**: 
  - 负载池创建成功
  - 策略配置正确保存

#### 测试用例 TC007: 负载均衡算法验证
- **测试步骤**:
  1. 选择不同的负载策略
  2. 执行多次测试请求
  3. 分析请求分布
- **预期结果**: 
  - 轮询: 请求均匀分布
  - 加权: 按权重比例分布
  - 最少连接: 选择连接最少的服务商

### 1.4 成本分析模块

#### 测试用例 TC008: 实时成本数据
- **测试步骤**:
  1. 查看成本分析页面
  2. 切换时间范围（今日、本周、本月、本年）
  3. 查看图表和明细
- **预期结果**: 
  - 显示真实的TOKEN消耗数据
  - 图表正确更新
  - 成本计算准确

#### 测试用例 TC009: 成本预警
- **测试步骤**:
  1. 设置成本阈值
  2. 模拟超出阈值
- **预期结果**: 
  - 触发预警通知
  - 记录预警日志

### 1.5 服务状态监控

#### 测试用例 TC010: 健康检查
- **测试步骤**:
  1. 执行健康检查
  2. 查看服务状态
  3. 模拟服务故障
- **预期结果**: 
  - 正确识别健康/故障状态
  - 熔断器正确触发
  - 故障转移生效

## 二、集成测试

### 2.1 模块间交互

#### 测试用例 IT001: 服务商配置与负载均衡集成
- **测试场景**: 新增服务商自动加入负载池
- **预期结果**: 
  - 新服务商可被负载均衡选择
  - 权重和优先级正确应用

#### 测试用例 IT002: 统一配置与API调用集成
- **测试场景**: 统一配置参数应用到实际API调用
- **预期结果**: 
  - API调用使用配置的参数
  - 参数覆盖优先级正确

#### 测试用例 IT003: 成本分析与服务调用集成
- **测试场景**: 每次API调用更新成本数据
- **预期结果**: 
  - 成本实时更新
  - Token消耗准确记录

### 2.2 前后端集成

#### 测试用例 IT004: API认证集成
- **测试场景**: 前端调用需要认证的后端API
- **预期结果**: 
  - JWT token正确传递
  - 未认证请求被拒绝

#### 测试用例 IT005: 实时数据同步
- **测试场景**: 后端数据变化实时反映到前端
- **预期结果**: 
  - WebSocket连接稳定
  - 数据更新及时

## 三、性能测试

### 3.1 响应时间测试

#### 测试用例 PT001: 页面加载性能
- **测试指标**:
  - 首屏加载时间 < 2秒
  - 完整加载时间 < 5秒
- **测试方法**: 使用Chrome DevTools测量

#### 测试用例 PT002: API响应时间
- **测试指标**:
  - 读取操作 < 200ms
  - 写入操作 < 500ms
- **测试方法**: 使用Postman批量测试

### 3.2 并发测试

#### 测试用例 PT003: 负载均衡并发处理
- **测试场景**: 100个并发请求
- **预期结果**: 
  - 无请求失败
  - 响应时间稳定
  - 负载分布均匀

#### 测试用例 PT004: 数据库连接池
- **测试场景**: 高并发数据库操作
- **预期结果**: 
  - 连接池正常工作
  - 无连接耗尽

### 3.3 压力测试

#### 测试用例 PT005: 系统极限测试
- **测试方法**: 逐步增加负载直到系统故障
- **测试指标**: 
  - 最大并发用户数
  - 最大请求处理能力
  - 故障恢复时间

## 四、安全测试

### 4.1 认证授权

#### 测试用例 ST001: JWT Token安全
- **测试点**:
  - Token过期验证
  - Token篡改检测
  - 刷新Token机制

#### 测试用例 ST002: 权限控制
- **测试点**:
  - 普通用户无法访问管理功能
  - 角色权限正确隔离

### 4.2 数据安全

#### 测试用例 ST003: API密钥保护
- **测试点**:
  - API密钥加密存储
  - 传输过程加密
  - 日志不泄露密钥

#### 测试用例 ST004: SQL注入防护
- **测试点**:
  - 参数化查询
  - 输入验证
  - 错误信息不暴露数据库结构

### 4.3 通信安全

#### 测试用例 ST005: HTTPS/WSS通信
- **测试点**:
  - 强制HTTPS
  - WebSocket使用WSS
  - 证书有效性

## 五、契约合规测试

### 5.1 数据库契约

#### 测试用例 CC001: 表结构验证
- **测试内容**:
  - AI_PROVIDERS表11个必填字段
  - SYSTEM_CONFIGS表JSON结构
  - 外键约束正确

#### 测试用例 CC002: 数据完整性
- **测试内容**:
  - 必填字段非空验证
  - 数据类型匹配
  - 唯一约束遵守

### 5.2 API契约

#### 测试用例 CC003: RESTful规范
- **测试内容**:
  - URL路径规范
  - HTTP方法正确使用
  - 响应格式统一

#### 测试用例 CC004: 错误处理契约
- **测试内容**:
  - 错误码规范
  - 错误消息格式
  - HTTP状态码正确

### 5.3 前端契约

#### 测试用例 CC005: 组件接口契约
- **测试内容**:
  - 组件props类型正确
  - 事件回调规范
  - 生命周期遵守

## 六、用户体验测试

### 6.1 界面测试

#### 测试用例 UX001: 响应式设计
- **测试设备**:
  - 桌面端（1920x1080）
  - 平板端（768x1024）
  - 移动端（375x667）- 仅用户端

#### 测试用例 UX002: 交互反馈
- **测试点**:
  - 加载状态显示
  - 操作成功/失败提示
  - 表单验证即时反馈

### 6.2 可用性测试

#### 测试用例 UX003: 操作流程
- **测试任务**:
  - 5分钟内完成服务商配置
  - 3分钟内创建负载池
  - 直观理解成本分析数据

#### 测试用例 UX004: 错误恢复
- **测试点**:
  - 网络断开恢复
  - 操作失败重试
  - 数据丢失预防

## 七、兼容性测试

### 7.1 浏览器兼容性

#### 测试用例 CT001: 主流浏览器
- **测试浏览器**:
  - Chrome 90+
  - Firefox 88+
  - Safari 14+
  - Edge 90+

### 7.2 部署环境兼容性

#### 测试用例 CT002: Railway部署
- **测试点**:
  - 环境变量正确读取
  - 数据库连接稳定
  - 静态资源正确加载

#### 测试用例 CT003: Vercel部署
- **测试点**:
  - Serverless函数正常
  - 边缘网络加速
  - 环境隔离

## 八、回归测试

### 8.1 核心功能回归

#### 测试用例 RT001: 每次发布前核心功能验证
- **测试清单**:
  - [ ] 登录认证
  - [ ] 服务商CRUD
  - [ ] 配置保存加载
  - [ ] 负载均衡选择
  - [ ] 成本数据展示

### 8.2 自动化回归

#### 测试用例 RT002: Jest单元测试
- **覆盖率要求**: ≥ 80%
- **执行命令**: `npm test`

## 测试执行计划

### 阶段一：单元测试（已完成）
- Jest框架搭建 ✅
- 核心模块测试 ✅
- 工具函数测试 ✅

### 阶段二：功能测试（进行中）
- 各模块功能验证
- 边界条件测试
- 异常处理测试

### 阶段三：集成测试
- 模块间交互
- 前后端集成
- 第三方服务集成

### 阶段四：非功能测试
- 性能测试
- 安全测试
- 兼容性测试

### 阶段五：用户验收测试
- 真实场景模拟
- 用户反馈收集
- 最终优化

## 测试报告模板

```
测试日期: [DATE]
测试版本: [VERSION]
测试人员: [TESTER]

测试概况:
- 总用例数: [TOTAL]
- 通过数: [PASSED]
- 失败数: [FAILED]
- 阻塞数: [BLOCKED]
- 通过率: [PASS_RATE]%

关键问题:
1. [ISSUE_1]
2. [ISSUE_2]

建议:
1. [SUGGESTION_1]
2. [SUGGESTION_2]
```

## 持续改进

1. **测试自动化**: 逐步提高自动化测试比例
2. **性能基准**: 建立性能基准线，持续监控
3. **安全审计**: 定期进行安全审计
4. **用户反馈**: 建立用户反馈机制

---

更新时间: 2025-01-28
测试版本: v3.0.0